{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. scraping data from the website with scrolling\n",
    "1-1. scoll to the bottom of best selling product page and scrape product id from products \\\n",
    "1-2. scraping review data from product page "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. scoll and save product id from products listed in the order of best selling product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# wait until available to scroll\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium setup\n",
    "path =  r\"C:\\Users\\z1one\\OneDrive\\바탕 화면\\chromedriver-win64\\chromedriver.exe\" # Update with the path to your ChromeDriver executable\n",
    "s = Service(path)\n",
    "driver = webdriver.Chrome(service=s)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Amazon 11st web page URL\n",
    "url = \"https://amazon.11st.co.kr/amazon/category?dispCtgr3No=1150107\"\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10) \n",
    "\n",
    "#스크롤 전의 스크롤바 높이\n",
    "before_h=driver.execute_script(\"return window.scrollY\")\n",
    "\n",
    "while True :\n",
    "    driver.find_element(by=By.CSS_SELECTOR, value=\"body\").send_keys(Keys.END) #맨 아래로 스크롤 내린다\n",
    "    time.sleep(2) #스크롤 하는 동안의 로딩시간\n",
    "    \n",
    "    \n",
    "    #스크롤 후의 스크롤바 높이\n",
    "    after_h=driver.execute_script(\"return window.scrollY\")\n",
    "    \n",
    "    if after_h==before_h:\n",
    "        break\n",
    "    before_h=after_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scroll to the end of the page\n",
    "def scroll_to_end(driver):\n",
    "    driver.find_element(By.CSS_SELECTOR, \"body\").send_keys(Keys.END)\n",
    "    time.sleep(2)  #\n",
    "\n",
    "# Selenium \n",
    "path =  r\"C:\\Users\\z1one\\OneDrive\\바탕 화면\\chromedriver-win64\\chromedriver.exe\"\n",
    "s = Service(path)\n",
    "driver = webdriver.Chrome(service=s)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Amazon 11st URL\n",
    "url = \"https://amazon.11st.co.kr/amazon/category?dispCtgr3No=1150107\"\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# scroll bar heigth before scroll     \n",
    "before_h = driver.execute_script(\"return window.scrollY\")\n",
    "\n",
    "# list to save product numbers\n",
    "product_numbers = []\n",
    "\n",
    "while len(product_numbers) < 10000:  # set maximum number of products\n",
    "    # scroll_to_end\n",
    "    scroll_to_end(driver)\n",
    "\n",
    "    # scroll bar heigth after scroll     \n",
    "    after_h = driver.execute_script(\"return window.scrollY\")\n",
    "\n",
    "    # if the scorll bar doesn't move stop\n",
    "    if after_h == before_h:\n",
    "        break\n",
    "\n",
    "    before_h = after_h\n",
    "\n",
    "    # Get the current page source\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find product numbers and add them to the list\n",
    "    a_tags = soup.find_all('a')\n",
    "    for a_tag in a_tags:\n",
    "        href = a_tag.get('href')\n",
    "        if href and \"products/\" in href:\n",
    "            product_number = href.split(\"products/\")[1]\n",
    "            product_numbers.append(product_number)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Save 1000 product numbers each\n",
    "file_counter = 1\n",
    "for i in range(0, len(product_numbers), 1000):\n",
    "    batch = product_numbers[i:i + 1000]\n",
    "    output_file = f\"product_numbers_{file_counter}.txt\" # set directory to save\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(\"\\n\".join(batch))\n",
    "    file_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. scraping review data from product page "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    792\u001b[0m     conn,\n\u001b[0;32m    793\u001b[0m     method,\n\u001b[0;32m    794\u001b[0m     url,\n\u001b[0;32m    795\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    796\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    797\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    798\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    799\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    800\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    801\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    802\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    803\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    806\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:492\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    491\u001b[0m         new_e \u001b[39m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mscheme)\n\u001b[1;32m--> 492\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\n\u001b[0;32m    494\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 468\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    469\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1097\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[1;32m-> 1097\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSystem time is way off (before \u001b[39m\u001b[39m{\u001b[39;00mRECENT_DATE\u001b[39m}\u001b[39;00m\u001b[39m). This will probably \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[39m=\u001b[39m _ssl_wrap_socket_and_match_hostname(\n\u001b[0;32m    643\u001b[0m     sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    644\u001b[0m     cert_reqs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_reqs,\n\u001b[0;32m    645\u001b[0m     ssl_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_version,\n\u001b[0;32m    646\u001b[0m     ssl_minimum_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_minimum_version,\n\u001b[0;32m    647\u001b[0m     ssl_maximum_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_maximum_version,\n\u001b[0;32m    648\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    649\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    650\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    651\u001b[0m     cert_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[0;32m    652\u001b[0m     key_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[0;32m    653\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[0;32m    654\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    655\u001b[0m     ssl_context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_context,\n\u001b[0;32m    656\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    657\u001b[0m     assert_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_hostname,\n\u001b[0;32m    658\u001b[0m     assert_fingerprint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_fingerprint,\n\u001b[0;32m    659\u001b[0m )\n\u001b[0;32m    660\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock_and_verified\u001b[39m.\u001b[39msocket\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    781\u001b[0m         server_hostname \u001b[39m=\u001b[39m normalized\n\u001b[1;32m--> 783\u001b[0m ssl_sock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    784\u001b[0m     sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    785\u001b[0m     keyfile\u001b[39m=\u001b[39;49mkey_file,\n\u001b[0;32m    786\u001b[0m     certfile\u001b[39m=\u001b[39;49mcert_file,\n\u001b[0;32m    787\u001b[0m     key_password\u001b[39m=\u001b[39;49mkey_password,\n\u001b[0;32m    788\u001b[0m     ca_certs\u001b[39m=\u001b[39;49mca_certs,\n\u001b[0;32m    789\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49mca_cert_dir,\n\u001b[0;32m    790\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49mca_cert_data,\n\u001b[0;32m    791\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    792\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[0;32m    793\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    794\u001b[0m )\n\u001b[0;32m    796\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\ssl_.py:471\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n\u001b[0;32m    472\u001b[0m \u001b[39mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\ssl_.py:515\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 515\u001b[0m \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    456\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    457\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    458\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    459\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    460\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    461\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    462\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    463\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1046\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1045\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1047\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1317\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1316\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1318\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    843\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[1;32m--> 845\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    846\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    847\u001b[0m )\n\u001b[0;32m    848\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m reraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[0;32m    471\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[1;32m---> 38\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m     39\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    792\u001b[0m     conn,\n\u001b[0;32m    793\u001b[0m     method,\n\u001b[0;32m    794\u001b[0m     url,\n\u001b[0;32m    795\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    796\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    797\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    798\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    799\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    800\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    801\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    802\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    803\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    806\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:492\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    491\u001b[0m         new_e \u001b[39m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mscheme)\n\u001b[1;32m--> 492\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\n\u001b[0;32m    494\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 468\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    469\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1097\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[1;32m-> 1097\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSystem time is way off (before \u001b[39m\u001b[39m{\u001b[39;00mRECENT_DATE\u001b[39m}\u001b[39;00m\u001b[39m). This will probably \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[39m=\u001b[39m _ssl_wrap_socket_and_match_hostname(\n\u001b[0;32m    643\u001b[0m     sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    644\u001b[0m     cert_reqs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_reqs,\n\u001b[0;32m    645\u001b[0m     ssl_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_version,\n\u001b[0;32m    646\u001b[0m     ssl_minimum_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_minimum_version,\n\u001b[0;32m    647\u001b[0m     ssl_maximum_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_maximum_version,\n\u001b[0;32m    648\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    649\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    650\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    651\u001b[0m     cert_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[0;32m    652\u001b[0m     key_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[0;32m    653\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[0;32m    654\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    655\u001b[0m     ssl_context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_context,\n\u001b[0;32m    656\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    657\u001b[0m     assert_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_hostname,\n\u001b[0;32m    658\u001b[0m     assert_fingerprint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_fingerprint,\n\u001b[0;32m    659\u001b[0m )\n\u001b[0;32m    660\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock_and_verified\u001b[39m.\u001b[39msocket\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    781\u001b[0m         server_hostname \u001b[39m=\u001b[39m normalized\n\u001b[1;32m--> 783\u001b[0m ssl_sock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    784\u001b[0m     sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    785\u001b[0m     keyfile\u001b[39m=\u001b[39;49mkey_file,\n\u001b[0;32m    786\u001b[0m     certfile\u001b[39m=\u001b[39;49mcert_file,\n\u001b[0;32m    787\u001b[0m     key_password\u001b[39m=\u001b[39;49mkey_password,\n\u001b[0;32m    788\u001b[0m     ca_certs\u001b[39m=\u001b[39;49mca_certs,\n\u001b[0;32m    789\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49mca_cert_dir,\n\u001b[0;32m    790\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49mca_cert_data,\n\u001b[0;32m    791\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    792\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[0;32m    793\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    794\u001b[0m )\n\u001b[0;32m    796\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\ssl_.py:471\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n\u001b[0;32m    472\u001b[0m \u001b[39mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\ssl_.py:515\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 515\u001b[0m \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    456\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    457\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    458\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    459\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    460\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    461\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    462\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    463\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1046\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1045\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1047\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1317\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1316\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1318\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\z1one\\OneDrive\\바탕 화면\\Portfolio_desktop\\eda\\0_product.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     product_numbers \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39msplitlines()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m output_filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00moutput_dir\u001b[39m}\u001b[39;00m\u001b[39m/df_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.xlsx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m scrape_and_save_reviews(product_numbers, output_filename)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m \u001b[39mprint\u001b[39m(i)\n",
      "\u001b[1;32mc:\\Users\\z1one\\OneDrive\\바탕 화면\\Portfolio_desktop\\eda\\0_product.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         base_url \u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://www.11st.co.kr/products/\u001b[39m\u001b[39m{\u001b[39;00mnum\u001b[39m}\u001b[39;00m\u001b[39m/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         req_parmas \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mreferer\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://www.11st.co.kr/products/\u001b[39m\u001b[39m{\u001b[39;00mnum\u001b[39m}\u001b[39;00m\u001b[39m/review-frame?page=1&pageTypCd=first&reviewDispYn=Y&isPreview=false&reviewOptDispYn=Y&optSearchBtnAndGraphLayer=Y&reviewBottomBtn=Y&openDetailContents=Y&pageSize=10&isIgnoreAuth=false&lctgrNo=1001312&leafCtgrNo=0&groupProductNo=0&groupFirstViewPrdNo=1717023653&selNo=44919358&prdTypCd=01&myProduct=false&kkukNo=0\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(base_url, params \u001b[39m=\u001b[39;49m req_parmas,  headers\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mUser-Agent\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m })\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         soup \u001b[39m=\u001b[39m BeautifulSoup(res\u001b[39m.\u001b[39mtext, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z1one/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Portfolio_desktop/eda/0_product.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         temp \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, class_\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mc_product_title c_product_title_style3\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mspan\u001b[39m\u001b[39m\"\u001b[39m, class_\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msub\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtext\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\z1one\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    503\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    504\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    505\u001b[0m         \u001b[39m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "# directory\n",
    "data_dir = 'data'\n",
    "output_dir = 'output'\n",
    "product_numbers_files = [f\"{data_dir}/product_numbers_{i}.txt\" for i in range(1, 2)]\n",
    "\n",
    "def scrape_and_save_reviews(product_numbers, output_filename):\n",
    "    review_cnt = 0\n",
    "    result = []\n",
    "    review_product_num_list = []\n",
    "    path =  r\"C:\\Users\\z1one\\OneDrive\\바탕 화면\\chromedriver-win64\\chromedriver.exe\"\n",
    "    s = Service(path)\n",
    "    # create option to hide widow\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=s, options  =options)\n",
    "\n",
    "    for num in product_numbers: # num = productnum\n",
    "        base_url =f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "        req_parmas = {\n",
    "                \"referer\":f\"https://www.11st.co.kr/products/{num}/review-frame?page=1&pageTypCd=first&reviewDispYn=Y&isPreview=false&reviewOptDispYn=Y&optSearchBtnAndGraphLayer=Y&reviewBottomBtn=Y&openDetailContents=Y&pageSize=10&isIgnoreAuth=false&lctgrNo=1001312&leafCtgrNo=0&groupProductNo=0&groupFirstViewPrdNo=1717023653&selNo=44919358&prdTypCd=01&myProduct=false&kkukNo=0\",\n",
    "\n",
    "            }\n",
    "        res = requests.get(base_url, params = req_parmas,  headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'\n",
    "})\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "        temp = soup.find(\"div\", class_= \"c_product_title c_product_title_style3\").find(\"span\", class_= \"sub\").text\n",
    "        \n",
    "        tot_num = int(re.findall(r\"\\d+\",temp)[0])\n",
    "        review_cnt += tot_num\n",
    "        \n",
    "        # product with reviews, scrape reviews\n",
    "        if (tot_num >0) :\n",
    "            for i in range(1, tot_num//10+2): \n",
    "                base_url =f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo={i}&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "                res = requests.get(base_url, params = req_parmas, headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'})\n",
    "                soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "                \n",
    "\n",
    "                for temp in soup.find_all(\"li\", class_=\"review_list_element\"):\n",
    "                        # customer id\n",
    "                        try:\n",
    "                            review_id = temp.find(\"dt\", class_=\"name\").text\n",
    "                        except:\n",
    "                            review_id = 0\n",
    "                        # review date\n",
    "                        try:\n",
    "                            review_date = temp.find(\"span\", class_=\"date\").text\n",
    "                        except:\n",
    "                            review_date = 0\n",
    "                        # review_rate\n",
    "                        try:\n",
    "                            review_rate = temp.find(\"p\", class_=\"grade\").find(\"em\").text\n",
    "                        except:\n",
    "                            review_rate = 0\n",
    "                        # korean\n",
    "                        try:\n",
    "                            review = temp.find(\"p\", class_=\"cont_review_hide\").text\n",
    "                            review = re.sub(r'\\xa0', ' ', review)  # replace \\xa0 with space\n",
    "                            review = re.sub(r'\\n', '', review)  # delete \\n\n",
    "                            review_text = review.strip()\n",
    "                        except:\n",
    "                            review_text = 0\n",
    "\n",
    "                        # review_option\n",
    "                        try:\n",
    "                            temp_opt = temp.find_all(\"div\", class_=\"option\")[1]\n",
    "                            review_option = temp_opt.text.replace(\"선택 옵션\", \"\").strip()\n",
    "                        except:\n",
    "                            review_option = 0\n",
    "\n",
    "                        # review_size\n",
    "                        try:\n",
    "                            review_size = temp.find(\"dl\", class_=\"option_set\").find_all(\"dd\")[0].text\n",
    "                        except:\n",
    "                            review_size = 0\n",
    "                        result.append([review_id,review_date,review_rate,review_text,review_option,review_size, num])\n",
    "        # save result as df and excel\n",
    "            result_df = pd.DataFrame(result)\n",
    "            result_df.to_excel(output_filename, index=False)\n",
    "\n",
    "    # initialize\n",
    "    result = []\n",
    "    review_product_num_list = []\n",
    "\n",
    "    # Merge all review data into one DataFrame\n",
    "    if os.path.exists(output_filename):\n",
    "        if os.path.getsize(output_filename) > 0:\n",
    "            if result_all_df is None:\n",
    "                result_all_df = pd.read_excel(output_filename)\n",
    "            else:\n",
    "                temp_df = pd.read_excel(output_filename)\n",
    "                result_all_df = pd.concat([result_all_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Collect and store review data for each product number\n",
    "for i, file in enumerate(product_numbers_files, start=1):\n",
    "    with open(file, 'r') as f:\n",
    "        product_numbers = f.read().splitlines()\n",
    "    output_filename = f\"{output_dir}/df_{i}.xlsx\"\n",
    "    scrape_and_save_reviews(product_numbers, output_filename)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다 되면 다음 셀 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory\n",
    "data_dir = 'data'\n",
    "output_dir = 'output'\n",
    "product_numbers_files = [f\"{data_dir}/product_numbers_{i}.txt\" for i in range(2, 12)]\n",
    "\n",
    "def scrape_and_save_reviews(product_numbers, output_filename):\n",
    "    review_cnt = 0\n",
    "    result = []\n",
    "    review_product_num_list = []\n",
    "    path =  r\"C:\\Users\\z1one\\OneDrive\\바탕 화면\\chromedriver-win64\\chromedriver.exe\"\n",
    "    s = Service(path)\n",
    "    # create option to hide widow\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=s, options  =options)\n",
    "\n",
    "\n",
    "    for num in product_numbers: # num = productnum\n",
    "        base_url =f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "        req_parmas = {\n",
    "                \"referer\":f\"https://www.11st.co.kr/products/{num}/review-frame?page=1&pageTypCd=first&reviewDispYn=Y&isPreview=false&reviewOptDispYn=Y&optSearchBtnAndGraphLayer=Y&reviewBottomBtn=Y&openDetailContents=Y&pageSize=10&isIgnoreAuth=false&lctgrNo=1001312&leafCtgrNo=0&groupProductNo=0&groupFirstViewPrdNo=1717023653&selNo=44919358&prdTypCd=01&myProduct=false&kkukNo=0\",\n",
    "\n",
    "            }\n",
    "        res = requests.get(base_url, params = req_parmas,  headers={'User-Agent':'Mozilla/5.0'})\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "        temp = soup.find(\"div\", class_= \"c_product_title c_product_title_style3\").find(\"span\", class_= \"sub\").text\n",
    "        \n",
    "        tot_num = int(re.findall(r\"\\d+\",temp)[0])\n",
    "        review_cnt += tot_num\n",
    "        \n",
    "        # product with reviews, scrape reviews\n",
    "        if (tot_num >0) :\n",
    "            for i in range(1, tot_num//10+2): \n",
    "                base_url =f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo={i}&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "                res = requests.get(base_url, params = req_parmas)\n",
    "                soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "                \n",
    "\n",
    "                for temp in soup.find_all(\"li\", class_=\"review_list_element\"):\n",
    "                        # customer id\n",
    "                        try:\n",
    "                            review_id = temp.find(\"dt\", class_=\"name\").text\n",
    "                        except:\n",
    "                            review_id = 0\n",
    "                        # review date\n",
    "                        try:\n",
    "                            review_date = temp.find(\"span\", class_=\"date\").text\n",
    "                        except:\n",
    "                            review_date = 0\n",
    "                        # review_rate\n",
    "                        try:\n",
    "                            review_rate = temp.find(\"p\", class_=\"grade\").find(\"em\").text\n",
    "                        except:\n",
    "                            review_rate = 0\n",
    "                        # korean\n",
    "                        try:\n",
    "                            review = temp.find(\"p\", class_=\"cont_review_hide\").text\n",
    "                            review = re.sub(r'\\xa0', ' ', review)  # replace \\xa0 with space\n",
    "                            review = re.sub(r'\\n', '', review)  # delete \\n\n",
    "                            review_text = review.strip()\n",
    "                        except:\n",
    "                            review_text = 0\n",
    "\n",
    "                        # review_option\n",
    "                        try:\n",
    "                            temp_opt = temp.find_all(\"div\", class_=\"option\")[1]\n",
    "                            review_option = temp_opt.text.replace(\"선택 옵션\", \"\").strip()\n",
    "                        except:\n",
    "                            review_option = 0\n",
    "\n",
    "                        # review_size\n",
    "                        try:\n",
    "                            review_size = temp.find(\"dl\", class_=\"option_set\").find_all(\"dd\")[0].text\n",
    "                        except:\n",
    "                            review_size = 0\n",
    "                        result.append([review_id,review_date,review_rate,review_text,review_option,review_size, num])\n",
    "        # save result as df and excel\n",
    "            result_df = pd.DataFrame(result)\n",
    "            result_df.to_excel(output_filename, index=False)\n",
    "\n",
    "    # initialize\n",
    "    result = []\n",
    "    review_product_num_list = []\n",
    "\n",
    "    # Merge all review data into one DataFrame\n",
    "    if os.path.exists(output_filename):\n",
    "        if os.path.getsize(output_filename) > 0:\n",
    "            if result_all_df is None:\n",
    "                result_all_df = pd.read_excel(output_filename)\n",
    "            else:\n",
    "                temp_df = pd.read_excel(output_filename)\n",
    "                result_all_df = pd.concat([result_all_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Collect and store review data for each product number\n",
    "for i, file in enumerate(product_numbers_files, start=1):\n",
    "    with open(file, 'r') as f:\n",
    "        product_numbers = f.read().splitlines()\n",
    "    output_filename = f\"{output_dir}/df_{i}.xlsx\"\n",
    "    scrape_and_save_reviews(product_numbers, output_filename)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 함수: 리뷰 데이터 수집 및 저장\n",
    "# def scrape_and_save_reviews(product_number, output_filename):\n",
    "#     result = []\n",
    "#     review_product_num_list = []\n",
    "#     path =  r\"C:\\Users\\z1one\\OneDrive\\바탕 화면\\chromedriver-win64\\chromedriver.exe\"\n",
    "#     s = Service(path)\n",
    "#     driver = webdriver.Chrome(service=s)\n",
    "\n",
    "#     for num in product_number:\n",
    "#         # 리뷰 데이터 수집 로직 \n",
    "#         base_url = f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\",\n",
    "#         req_params = {\n",
    "#                 \"referer\": f\"https://www.11st.co.kr/products/{num}/review-frame?page=1&pageTypCd=first&reviewDispYn=Y&isPreview=false&reviewOptDispYn=Y&optSearchBtnAndGraphLayer=Y&reviewBottomBtn=Y&openDetailContents=Y&pageSize=10&isIgnoreAuth=false&lctgrNo=1001312&leafCtgrNo=0&groupProductNo=0&groupFirstViewPrdNo=1717023653&selNo=44919358&prdTypCd=01&myProduct=false&kkukNo=0\",\n",
    "#             }\n",
    "#         res = requests.get(base_url, params=req_params)\n",
    "#         soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "#         temp = soup.find(\"div\", class_=\"c_product_title c_product_title_style3\").find(\"span\", class_=\"sub\").text\n",
    "\n",
    "#         tot_num = int(re.findall(r\"\\d+\", temp)[0])\n",
    "\n",
    "#         # product with reviews, scrape reviews\n",
    "#         if tot_num > 0:\n",
    "#             # if there's a button click\n",
    "#             base_url = f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#             driver.get(base_url)\n",
    "#             driver.maximize_window()\n",
    "#             driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "#             btn_path = '//*[@id=\"review-list-page-area\"]/div[2]/button'\n",
    "#             driver.find_element(By.XPATH, btn_path).click()\n",
    "\n",
    "#             for i in range(1, tot_num // 10 + 2):\n",
    "#                 base_url = f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo={i}&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#                 res = requests.get(base_url, params=req_params)\n",
    "#                 soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "#                 # 스크랩한 리뷰 데이터 저장\n",
    "#                 for temp in soup.find_all(\"li\", class_=\"review_list_element\"):\n",
    "#                     # customer id\n",
    "#                     try:\n",
    "#                         review_id = temp.find(\"dt\", class_=\"name\").text\n",
    "#                     except:\n",
    "#                         review_id = 0\n",
    "#                     # review date\n",
    "#                     try:\n",
    "#                         review_date = temp.find(\"span\", class_=\"date\").text\n",
    "#                     except:\n",
    "#                         review_date = 0\n",
    "#                     # review_rate\n",
    "#                     try:\n",
    "#                         review_rate = temp.find(\"p\", class_=\"grade\").find(\"em\").text\n",
    "#                     except:\n",
    "#                         review_rate = 0\n",
    "#                     # korean\n",
    "#                     try:\n",
    "#                         review = temp.find(\"p\", class_=\"cont_review_hide\").text\n",
    "#                         review = re.sub(r'\\xa0', ' ', review)  # replace \\xa0 with space\n",
    "#                         review = re.sub(r'\\n', '', review)  # delete \\n\n",
    "#                         review_text = review.strip()\n",
    "#                     except:\n",
    "#                         review_text = 0\n",
    "\n",
    "#                     # review_option\n",
    "#                     try:\n",
    "#                         temp_opt = temp.find_all(\"div\", class_=\"option\")[1]\n",
    "#                         review_option = temp_opt.text.replace(\"선택 옵션\", \"\").strip()\n",
    "#                     except:\n",
    "#                         review_option = 0\n",
    "\n",
    "#                     # review_size\n",
    "#                     try:\n",
    "#                         review_size = temp.find(\"dl\", class_=\"option_set\").find_all(\"dd\")[0].text\n",
    "#                     except:\n",
    "#                         review_size = 0\n",
    "\n",
    "#                     result.append([review_id, review_date, review_rate, review_text, review_option, review_size, num])\n",
    "\n",
    "#         # 결과를 파일로 저장\n",
    "#         result_df = pd.DataFrame(result)\n",
    "#         result_df.to_excel(output_filename, index=False)\n",
    "\n",
    "#         # 초기화\n",
    "#         result = []\n",
    "#         review_product_num_list = []\n",
    "\n",
    "#         # 모든 리뷰 데이터를 하나의 DataFrame으로 병합\n",
    "#         if os.path.exists(output_filename):\n",
    "#             if os.path.getsize(output_filename) > 0:\n",
    "#                 if result_all_df is None:\n",
    "#                     result_all_df = pd.read_excel(output_filename)\n",
    "#                 else:\n",
    "#                     temp_df = pd.read_excel(output_filename)\n",
    "#                     result_all_df = pd.concat([result_all_df, temp_df], ignore_index=True)\n",
    "\n",
    "# # 모든 리뷰 데이터를 저장할 DataFrame 초기화\n",
    "# result_all_df = None\n",
    "\n",
    "# # 각 상품 번호에 대한 리뷰 데이터 수집 및 저장\n",
    "# for i, file in enumerate(product_numbers_files, start=1):\n",
    "#     with open(file, 'r') as f:\n",
    "#         product_numbers = f.read().splitlines()\n",
    "#     output_filename = f\"{output_dir}/df_{i}.xlsx\"\n",
    "#     scrape_and_save_reviews(product_numbers, output_filename)\n",
    "\n",
    "# # result_all_df를 Excel 파일로 저장\n",
    "# if result_all_df is not None:\n",
    "#     result_all_df.to_excel(f\"{output_dir}/result_all_df.xlsx\", index=False)\n",
    "\n",
    "# print(\"All Data Merged and Saved as result_all_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [f\"{data_dir}/product_numbers_{i}.txt\" for i in range(1, 12)]\n",
    "# for i, file in enumerate(product_numbers_files, start=1):\n",
    "#     with open(file, 'r') as f:\n",
    "#         product_numbers = f.read().splitlines()\n",
    "#     output_filename = f\"{output_dir}/df_{i}.xlsx\"\n",
    "#     scrape_and_save_reviews(product_numbers, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_cnt = 0\n",
    "# result= []\n",
    "# for i, file in enumerate(product_numbers_files, start=1):\n",
    "#     with open(file, 'r') as f:\n",
    "#         product_numbers = f.read().splitlines()\n",
    "\n",
    "# for num in product_numbers: # num = productnum\n",
    "#     base_url =f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#     req_parmas = {\n",
    "#             \"referer\":f\"https://www.11st.co.kr/products/{num}/review-frame?page=1&pageTypCd=first&reviewDispYn=Y&isPreview=false&reviewOptDispYn=Y&optSearchBtnAndGraphLayer=Y&reviewBottomBtn=Y&openDetailContents=Y&pageSize=10&isIgnoreAuth=false&lctgrNo=1001312&leafCtgrNo=0&groupProductNo=0&groupFirstViewPrdNo=1717023653&selNo=44919358&prdTypCd=01&myProduct=false&kkukNo=0\",\n",
    "\n",
    "#         }\n",
    "#     res = requests.get(base_url, params = req_parmas)\n",
    "#     soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "#     temp = soup.find(\"div\", class_= \"c_product_title c_product_title_style3\").find(\"span\", class_= \"sub\").text\n",
    "    \n",
    "    \n",
    "#     tot_num = int(re.findall(r\"\\d+\",temp)[0])\n",
    "#     review_cnt += tot_num\n",
    "    \n",
    "#     # 리뷰가 있는 건에 대해 페이지 돌리는 부분\n",
    "#     if (tot_num >0) :\n",
    "#         for i in range(1, tot_num//10+2): # 수정한 부분\n",
    "#             base_url =f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo={i}&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#             res = requests.get(base_url, params = req_parmas)\n",
    "#             soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "            \n",
    "#             # 리뷰 모으는 부분\n",
    "#             for temp in soup.find_all(\"li\", class_= \"review_list_element\"):                      \n",
    "#                  # 아이디\n",
    "#                     try: \n",
    "#                         review_id = temp.find(\"dt\", class_= \"name\").text\n",
    "#                     except:\n",
    "#                         review_id = 0\n",
    "#                     # 리뷰 날짜\n",
    "#                     try: \n",
    "#                         review_date = temp.find(\"span\", class_= \"date\").text\n",
    "#                     except:\n",
    "#                         review_date = 0\n",
    "#                     # 리뷰 평점\n",
    "#                     try:\n",
    "#                         review_rate = temp.find(\"p\", class_= \"grade\").find(\"em\").text\n",
    "#                     except: \n",
    "#                         review_rate = 0\n",
    "#                     # 한글 리뷰\n",
    "#                     import re\n",
    "#                     try: \n",
    "#                         review = temp.find(\"p\", class_=\"cont_review_hide\").text\n",
    "#                         review = re.sub(r'\\xa0', ' ', review)  # \\xa0을 스페이스로 대체\n",
    "#                         review = re.sub(r'\\n', '', review)  # \\n을 제거\n",
    "#                         review_text = review.strip()\n",
    "#                     except:\n",
    "#                         review_text = 0\n",
    "\n",
    "#                     # 선택 옵션 \n",
    "#                     try: \n",
    "#                         temp_opt = temp.find_all(\"div\",class_ = \"option\")[1]\n",
    "#                         review_option = temp_opt.text.replace(\"선택 옵션\", \"\").strip()\n",
    "#                     except: \n",
    "#                         review_option = 0\n",
    "\n",
    "#                     # 사이즈 정보\n",
    "#                     try: \n",
    "#                         review_size = temp.find(\"dl\", class_= \"option_set\").find_all(\"dd\")[0].text\n",
    "#                     except:\n",
    "#                         review_size = 0\n",
    "\n",
    "\n",
    "#                     result.append([review_id,review_date,review_rate,review_text,review_option,review_size, num])\n",
    "                   \n",
    "                    \n",
    "                \n",
    "# result_df = pd.DataFrame(result) \n",
    "# result_df.to_excel(\"final_df_3.xlsx\")\n",
    "\n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = []\n",
    "# review_product_num_list = []\n",
    "\n",
    "# for i, num in enumerate(product_numbers, start=1):  # enumerate를 사용하여 숫자를 추가\n",
    "#     base_url = f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#     req_params = {\n",
    "#         \"referer\": f\"https://www.11st.co.kr/products/{num}/review-frame?page=1&pageTypCd=first&reviewDispYn=Y&isPreview=false&reviewOptDispYn=Y&optSearchBtnAndGraphLayer=Y&reviewBottomBtn=Y&openDetailContents=Y&pageSize=10&isIgnoreAuth=false&lctgrNo=1001312&leafCtgrNo=0&groupProductNo=0&groupFirstViewPrdNo=1717023653&selNo=44919358&prdTypCd=01&myProduct=false&kkukNo=0\",\n",
    "#     }\n",
    "#     res = requests.get(base_url, params=req_params)\n",
    "#     soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "#     temp = soup.find(\"div\", class_=\"c_product_title c_product_title_style3\").find(\"span\", class_=\"sub\").text\n",
    "\n",
    "#     tot_num = int(re.findall(r\"\\d+\", temp)[0])\n",
    "\n",
    "#     # product with reviews, scrape reviews\n",
    "#     if tot_num > 0:\n",
    "#         # if there's a button click\n",
    "#         base_url = f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#         driver.get(base_url)\n",
    "#         driver.maximize_window()\n",
    "#         driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "#         btn_path = '//*[@id=\"review-list-page-area\"]/div[2]/button'\n",
    "#         driver.find_element(By.XPATH, btn_path).click()\n",
    "\n",
    "#         for i in range(1, tot_num // 10 + 2):\n",
    "#             base_url = f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo={i}&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#             res = requests.get(base_url, params=req_params)\n",
    "#             soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "#             # 스크랩한 리뷰 데이터 저장\n",
    "#             for temp in soup.find_all(\"li\", class_=\"review_list_element\"):\n",
    "#                 # customer id\n",
    "#                 try:\n",
    "#                     review_id = temp.find(\"dt\", class_=\"name\").text\n",
    "#                 except:\n",
    "#                     review_id = 0\n",
    "#                 # review date\n",
    "#                 try:\n",
    "#                     review_date = temp.find(\"span\", class_=\"date\").text\n",
    "#                 except:\n",
    "#                     review_date = 0\n",
    "#                 # review_rate\n",
    "#                 try:\n",
    "#                     review_rate = temp.find(\"p\", class_=\"grade\").find(\"em\").text\n",
    "#                 except:\n",
    "#                     review_rate = 0\n",
    "#                 # korean\n",
    "#                 try:\n",
    "#                     review = temp.find(\"p\", class_=\"cont_review_hide\").text\n",
    "#                     review = re.sub(r'\\xa0', ' ', review)  # replace \\xa0 with space\n",
    "#                     review = re.sub(r'\\n', '', review)  # delete \\n\n",
    "#                     review_text = review.strip()\n",
    "#                 except:\n",
    "#                     review_text = 0\n",
    "\n",
    "#                 # review_option\n",
    "#                 try:\n",
    "#                     temp_opt = temp.find_all(\"div\", class_=\"option\")[1]\n",
    "#                     review_option = temp_opt.text.replace(\"선택 옵션\", \"\").strip()\n",
    "#                 except:\n",
    "#                     review_option = 0\n",
    "\n",
    "#                 # review_size\n",
    "#                 try:\n",
    "#                     review_size = temp.find(\"dl\", class_=\"option_set\").find_all(\"dd\")[0].text\n",
    "#                 except:\n",
    "#                     review_size = 0\n",
    "\n",
    "#                 result.append([review_id, review_date, review_rate, review_text, review_option, review_size, num])\n",
    "#                 review_product_num_list.append([num, id_review_cnt])\n",
    "\n",
    "#     # 결과를 파일로 저장 (파일 이름에 숫자 추가)\n",
    "#     result_df = pd.DataFrame(result)\n",
    "#     result_df.to_excel(f\"df_{i}.xlsx\", index=False)\n",
    "\n",
    "#     review_product_num_list_df = pd.DataFrame(review_product_num_list)\n",
    "#     review_product_num_list_df.to_excel(f\"list_{i}.xlsx\", index=False)\n",
    "\n",
    "#     result = []  # 결과 초기화\n",
    "#     review_product_num_list = []  # 리스트 초기화\n",
    "\n",
    "# print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 빈 DataFrame 생성\n",
    "# result_all_df = pd.DataFrame(columns=[\"Customer ID\", \"Review Date\", \"Review Rate\", \"Review Text\", \"Review Option\", \"Review Size\", \"Product Number\"])\n",
    "\n",
    "# # 각 df 파일을 읽어와 병합\n",
    "# for i in range(1, 12):  # 파일 수에 따라 범위 조절 (1부터 11까지)\n",
    "#     file_name = f\"df_{i}.xlsx\"\n",
    "#     df = pd.read_excel(file_name, index_col=0)\n",
    "#     result_all_df = pd.concat([result_all_df, df], ignore_index=True)\n",
    "\n",
    "# # 병합된 DataFrame을 하나의 Excel 파일로 저장\n",
    "# result_all_df.to_excel(\"result_all_df.xlsx\", index=False)\n",
    "\n",
    "# print(\"All Data Merged and Saved as result_all_df.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # num = 5501668011\n",
    "\n",
    "# # if there's a button, click by selenium. Otherwise, scrape data \n",
    "\n",
    "# product_num_list = ['3582216563', '3581969180', '3575728745', '3553883972', '3553773267', '3548619969', '3547722066', '3538668940', '5749296973', '5736750071', '5734222597', '5730209511', '5727478506', '5724948577', '5724093100', '5721562544', '5718004842', '5713005354', '5712891127', '5710181243', '5709558715', '5706354212', '5705711313', '5702525032', '5690431293', '5686143338', '5682303672', '5682151133', '5681376359', '5663709514', '5663337278', '5662789155', '5661810504', '5647350718', '5645900049', '5645263952', '5643503235', '5632378103', '5628970761', '5608429523', '5601040035', '5593070811', '5582168281', '5580332878', '5575242450', '5571587220', '5568539325', '5560769703', '5557923041', '5555079652', '5552034477', '5551956038', '5551887783', '5550391662', '5549340987', '5548984301', '5548942666', '5548504097', '5548223301', '5546765257', '5546404656', '5546351791', '5544494220', '5543955070', '5543127192', '5541456702', '5540774677', '5540721839', '5540498884', '5540333989', '5540193784', '5539758737', '5539492248', '5539165026', '5537376806', '5537348007', '5537087058', '5536658636', '5536168116', '5535807311', '5534529663', '5534151756', '5533889665', '5532675757', '5532310394', '5532294502', '5529098186', '5527825277', '5524167392', '5511392395', '5501668011', '5456386311', '5440430637', '5428179751', '5419128309', '5384523822', '5352369554', '5351971255', '5282000509', '5248705272', '5226162096', '5226091695', '5209693816', '5191096353', '5166400682', '5116795751', '5073087508', '5054357353', '4958845288', '4911938299', '4843125819', '4812183210', '4797994063', '4742853021', '4703366249', '4697194978', '4673615555', '4651107738', '4519249467', '4474093988', '4465828899', '4461303463', '4430906060', '4419233746', '4418745988', '4417269575', '4415431195', '4415324010', '4415317334', '4329864647', '4311192497', '4303286103', '4272897183', '4240473895', '4030360740', '3980154902', '3943416786', '3921300976', '3874704817', '3850694187', '3843099414', '3780784961', '3772067959', '3738968489', '3714019020', '3694147974', '3643006671']\n",
    "\n",
    "\n",
    "# result = []\n",
    "# # count the number of review pages\n",
    "# for num in product_num_list: # num = productnum\n",
    "#     base_url =f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#     req_parmas = {\n",
    "#             \"referer\":f\"https://www.11st.co.kr/products/{num}/review-frame?page=1&pageTypCd=first&reviewDispYn=Y&isPreview=false&reviewOptDispYn=Y&optSearchBtnAndGraphLayer=Y&reviewBottomBtn=Y&openDetailContents=Y&pageSize=10&isIgnoreAuth=false&lctgrNo=1001312&leafCtgrNo=0&groupProductNo=0&groupFirstViewPrdNo=1717023653&selNo=44919358&prdTypCd=01&myProduct=false&kkukNo=0\",\n",
    "\n",
    "#         }\n",
    "#     res = requests.get(base_url, params = req_parmas)\n",
    "#     soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "#     temp = soup.find(\"div\", class_= \"c_product_title c_product_title_style3\").find(\"span\", class_= \"sub\").text\n",
    "    \n",
    "#     tot_num = int(re.findall(r\"\\d+\",temp)[0])\n",
    "    \n",
    "#     # product with reviews, scrape reviews \n",
    "#     if (tot_num >0) :\n",
    "#         # if there's a button click \n",
    "#         base_url =f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo=1&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#         driver.get(base_url)\n",
    "#         driver.maximize_window()        \n",
    "#         driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")        \n",
    "#         btn_path = '//*[@id=\"review-list-page-area\"]/div[2]/button'\n",
    "#         driver.find_element(By.XPATH,btn_path).click()\n",
    "        \n",
    "        \n",
    "#         for i in range(1, tot_num//10+2): \n",
    "#             base_url =f\"https://www.11st.co.kr/products/{num}/review-list??pageSize=10&pageNo={i}&myProduct=false&pntVals=&rtype=&sortType=01&themeNm=&optNm=&kkukNo=0\"\n",
    "#             res = requests.get(base_url, params = req_parmas)\n",
    "#             soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "            \n",
    "#             # scraping review data\n",
    "#             for temp in soup.find_all(\"li\", class_= \"review_list_element\"):                      \n",
    "#                  # customer id\n",
    "#                     try: \n",
    "#                         review_id = temp.find(\"dt\", class_= \"name\").text\n",
    "#                     except:\n",
    "#                         review_id = 0\n",
    "#                     # review date\n",
    "#                     try: \n",
    "#                         review_date = temp.find(\"span\", class_= \"date\").text\n",
    "#                     except:\n",
    "#                         review_date = 0\n",
    "#                     # review_rate\n",
    "#                     try:\n",
    "#                         review_rate = temp.find(\"p\", class_= \"grade\").find(\"em\").text\n",
    "#                     except: \n",
    "#                         review_rate = 0\n",
    "#                     # korean \n",
    "#                     try: \n",
    "#                         review = temp.find(\"p\", class_=\"cont_review_hide\").text\n",
    "#                         review = re.sub(r'\\xa0', ' ', review)  # replace \\xa0 with space\n",
    "#                         review = re.sub(r'\\n', '', review)  # delete \\n\n",
    "#                         review_text = review.strip()\n",
    "#                     except:\n",
    "#                         review_text = 0\n",
    "\n",
    "#                     # review_option\n",
    "#                     try: \n",
    "#                         temp_opt = temp.find_all(\"div\",class_ = \"option\")[1]\n",
    "#                         review_option = temp_opt.text.replace(\"선택 옵션\", \"\").strip()\n",
    "#                     except: \n",
    "#                         review_option = 0\n",
    "\n",
    "#                     # review_size\n",
    "#                     try: \n",
    "#                         review_size = temp.find(\"dl\", class_= \"option_set\").find_all(\"dd\")[0].text\n",
    "#                     except:\n",
    "#                         review_size = 0\n",
    "\n",
    "\n",
    "#                     result.append([review_id,review_date,review_rate,review_text,review_option,review_size, num])\n",
    "                    \n",
    "                    \n",
    "                \n",
    "# result_df = pd.DataFrame(result) \n",
    "# result_df.to_excel(\"df_1.xlsx\")\n",
    "\n",
    "# review_product_num_list_df = pd.DataFrame(review_product_num_list)\n",
    "# review_product_num_list_df.to_excel(\"list_1.xlsx\")\n",
    "\n",
    "# print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
